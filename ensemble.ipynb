{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Simple example of a homogeneous ensemble using learning networks"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "In this simple example, no bagging is used, so every atomic model\n",
    "gets the same learned parameters, unless the atomic model training\n",
    "algorithm has randomness, eg, DecisionTree with random subsampling\n",
    "of features at nodes."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Plots.PyPlotBackend()"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "using Plots; pyplot()"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "learning network (composite model spec):"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Base.Generator{UnitRange{Int64},Main.##471.var\"#1#2\"}(Main.##471.var\"#1#2\"(), 1:100)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "Xs = source()\n",
    "ys = source(kind=:target)\n",
    "\n",
    "atom = @load DecisionTreeRegressor\n",
    "atom.n_subfeatures = 4 # to ensure diversity among trained atomic models\n",
    "\n",
    "machines = (machine(atom, Xs, ys) for i in 1:100)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "overload summation for nodes:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Base.sum(v...) = sum(v)\n",
    "Base.sum(v::AbstractVector{<:AbstractNode}) = node(sum, v...)\n",
    "\n",
    "yhat = sum([predict(m, Xs) for  m in machines]);"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "new composite model type and instance:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Main.##471.OneHundredModels(atom = DecisionTreeRegressor(pruning_purity_threshold = 0.0,\n                                                         max_depth = -1,\n                                                         min_samples_leaf = 5,\n                                                         min_samples_split = 2,\n                                                         min_purity_increase = 0.0,\n                                                         n_subfeatures = 4,\n                                                         post_prune = false,),)\u001b[34m @ 7…01\u001b[39m"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "one_hundred_models = @from_network OneHundredModels(atom=atom) <= yhat"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "application to data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X, y = @load_boston;"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "tune regularization parameter for a *single* tree:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DeterministicTunedModel} @ 7…10\u001b[39m.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/machines.jl:172\n",
      "\rIterating over a 26-point grid:  11%[==>                      ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  15%[===>                     ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  19%[====>                    ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  22%[=====>                   ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  26%[======>                  ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  30%[=======>                 ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  33%[========>                ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  37%[=========>               ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  41%[==========>              ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  44%[===========>             ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  48%[============>            ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  52%[============>            ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  56%[=============>           ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  59%[==============>          ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  63%[===============>         ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  67%[================>        ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  70%[=================>       ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  74%[==================>      ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  78%[===================>     ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  81%[====================>    ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  85%[=====================>   ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  89%[======================>  ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  93%[=======================> ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  96%[========================>]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid: 100%[=========================] Time: 0:00:00\u001b[K\n",
      "┌ Info: Training of best model suppressed.\n",
      "│  To train tuning machine `mach` on all supplied data, call `fit!(mach.fitresult)`.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/tuning.jl:316\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "r = range(atom,\n",
    "          :min_samples_split,\n",
    "          lower=2,\n",
    "          upper=100, scale=:log)\n",
    "\n",
    "mach = machine(atom, X, y)\n",
    "\n",
    "curve = learning_curve!(mach,\n",
    "                        range=r,\n",
    "                        measure=mav,\n",
    "                        resampling=CV(nfolds=9))\n",
    "\n",
    "plot(curve.parameter_values, curve.measurements, xlab=curve.parameter_name)\n",
    "savefig(\"atom.png\")"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "tune regularization parameter for all trees in ensemble simultaneously:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DeterministicTunedModel} @ 5…93\u001b[39m.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/machines.jl:172\n",
      "\rIterating over a 26-point grid:   4%[>                        ]  ETA: 0:00:00\u001b[K\rIterating over a 26-point grid:  11%[==>                      ]  ETA: 0:00:10\u001b[K\rIterating over a 26-point grid:  15%[===>                     ]  ETA: 0:00:12\u001b[K\rIterating over a 26-point grid:  19%[====>                    ]  ETA: 0:00:12\u001b[K\rIterating over a 26-point grid:  22%[=====>                   ]  ETA: 0:00:12\u001b[K\rIterating over a 26-point grid:  26%[======>                  ]  ETA: 0:00:12\u001b[K\rIterating over a 26-point grid:  30%[=======>                 ]  ETA: 0:00:12\u001b[K\rIterating over a 26-point grid:  33%[========>                ]  ETA: 0:00:12\u001b[K\rIterating over a 26-point grid:  37%[=========>               ]  ETA: 0:00:11\u001b[K\rIterating over a 26-point grid:  41%[==========>              ]  ETA: 0:00:11\u001b[K\rIterating over a 26-point grid:  44%[===========>             ]  ETA: 0:00:10\u001b[K\rIterating over a 26-point grid:  48%[============>            ]  ETA: 0:00:09\u001b[K\rIterating over a 26-point grid:  52%[============>            ]  ETA: 0:00:09\u001b[K\rIterating over a 26-point grid:  56%[=============>           ]  ETA: 0:00:08\u001b[K\rIterating over a 26-point grid:  59%[==============>          ]  ETA: 0:00:07\u001b[K\rIterating over a 26-point grid:  63%[===============>         ]  ETA: 0:00:07\u001b[K\rIterating over a 26-point grid:  67%[================>        ]  ETA: 0:00:06\u001b[K\rIterating over a 26-point grid:  70%[=================>       ]  ETA: 0:00:05\u001b[K\rIterating over a 26-point grid:  74%[==================>      ]  ETA: 0:00:05\u001b[K\rIterating over a 26-point grid:  78%[===================>     ]  ETA: 0:00:04\u001b[K\rIterating over a 26-point grid:  81%[====================>    ]  ETA: 0:00:03\u001b[K\rIterating over a 26-point grid:  85%[=====================>   ]  ETA: 0:00:03\u001b[K\rIterating over a 26-point grid:  89%[======================>  ]  ETA: 0:00:02\u001b[K\rIterating over a 26-point grid:  93%[=======================> ]  ETA: 0:00:01\u001b[K\rIterating over a 26-point grid:  96%[========================>]  ETA: 0:00:01\u001b[K\rIterating over a 26-point grid: 100%[=========================] Time: 0:00:17\u001b[K\n",
      "┌ Info: Training of best model suppressed.\n",
      "│  To train tuning machine `mach` on all supplied data, call `fit!(mach.fitresult)`.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/tuning.jl:316\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "r = range(one_hundred_models,\n",
    "          :(atom.min_samples_split),\n",
    "          lower=2,\n",
    "          upper=100, scale=:log)\n",
    "\n",
    "mach = machine(one_hundred_models, X, y)\n",
    "\n",
    "curve = learning_curve!(mach,\n",
    "                        range=r,\n",
    "                        measure=mav,\n",
    "                        resampling=CV(nfolds=9))\n",
    "\n",
    "plot(curve.parameter_values, curve.measurements, xlab=curve.parameter_name)\n",
    "savefig(\"ensemble.png\")"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  },
  "kernelspec": {
   "name": "julia-1.3",
   "display_name": "Julia 1.3.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
